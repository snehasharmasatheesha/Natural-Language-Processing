{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "541d9eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\sneha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We import and download the gutenberg text corpus\n",
    "#NLTK includes a small selection of texts from the Project Gutenberg electronic text archive, \n",
    "#which contains some 25,000 free electronic books, hosted at http://www.gutenberg.org/.\n",
    "import bamboolib as bam \n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "import numpy as np\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d5a50a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt' 'austen-persuasion.txt' 'austen-sense.txt'\n",
      " 'bible-kjv.txt' 'blake-poems.txt' 'bryant-stories.txt'\n",
      " 'burgess-busterbrown.txt' 'carroll-alice.txt' 'chesterton-ball.txt'\n",
      " 'chesterton-brown.txt' 'chesterton-thursday.txt' 'edgeworth-parents.txt'\n",
      " 'melville-moby_dick.txt' 'milton-paradise.txt' 'shakespeare-caesar.txt'\n",
      " 'shakespeare-hamlet.txt' 'shakespeare-macbeth.txt' 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "fileids=gutenberg.fileids()#each file is a source will be displayed\n",
    "print(np.array(fileids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b8f8dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   can  could    may  might   will  would should \n",
      "    88     49     85     26    261     85     42 \n"
     ]
    }
   ],
   "source": [
    "modals=['can', 'could', 'may', 'might', 'will', 'would', 'should']\n",
    "for fileids in gutenberg.fileids():\n",
    "    fd=nltk.FreqDist((word) for word in gutenberg.words(fileids) if word in modals)\n",
    "fd.tabulate(samples=modals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe4f4045",
   "metadata": {},
   "outputs": [],
   "source": [
    "least=nltk.FreqDist(dict(fd.most_common()[-1:]))\n",
    "most=nltk.FreqDist(dict(fd.most_common()[:1]))\n",
    "least_used_word=list(least.keys())[0]\n",
    "most_used_word=list(most.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20b16878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           can  could    may  might   will  would should \n",
      "        austen-emma.txt    270    825    213    322    559    815    366 \n",
      "  austen-persuasion.txt    100    444     87    166    162    351    185 \n",
      "       austen-sense.txt    206    568    169    215    354    507    228 \n",
      "          bible-kjv.txt    213    165   1024    475   3807    443    768 \n",
      "        blake-poems.txt     20      3      5      2      3      3      6 \n",
      "     bryant-stories.txt     75    154     18     23    144    110     38 \n",
      "burgess-busterbrown.txt     23     56      3     17     19     46     13 \n",
      "      carroll-alice.txt     57     73     11     28     24     70     27 \n",
      "    chesterton-ball.txt    131    117     90     69    198    139     75 \n",
      "   chesterton-brown.txt    126    170     47     71    111    132     56 \n",
      "chesterton-thursday.txt    117    148     56     71    109    116     54 \n",
      "  edgeworth-parents.txt    340    420    160    127    517    503    271 \n",
      " melville-moby_dick.txt    220    215    230    183    379    421    181 \n",
      "    milton-paradise.txt    107     62    116     98    161     49     55 \n",
      " shakespeare-caesar.txt     16     18     35     12    129     40     38 \n",
      " shakespeare-hamlet.txt     33     26     56     28    131     60     52 \n",
      "shakespeare-macbeth.txt     21     15     30      5     62     42     41 \n",
      "     whitman-leaves.txt     88     49     85     26    261     85     42 \n"
     ]
    }
   ],
   "source": [
    "cfd=nltk.ConditionalFreqDist((fileids,word) for fileids in gutenberg.fileids() \n",
    "                             for word in gutenberg.words(fileids) if word in modals)\n",
    "modals=['can', 'could', 'may', 'might', 'will', 'would', 'should']\n",
    "cfd.tabulate(fileids,samples=modals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4143bf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3ceae6dcd74a00909d29eeee356191"
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>would</th>\n",
       "      <th>could</th>\n",
       "      <th>might</th>\n",
       "      <th>will</th>\n",
       "      <th>may</th>\n",
       "      <th>should</th>\n",
       "      <th>can</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>austen-emma.txt</th>\n",
       "      <td>815</td>\n",
       "      <td>825</td>\n",
       "      <td>322</td>\n",
       "      <td>559</td>\n",
       "      <td>213</td>\n",
       "      <td>366</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>austen-persuasion.txt</th>\n",
       "      <td>351</td>\n",
       "      <td>444</td>\n",
       "      <td>166</td>\n",
       "      <td>162</td>\n",
       "      <td>87</td>\n",
       "      <td>185</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>austen-sense.txt</th>\n",
       "      <td>507</td>\n",
       "      <td>568</td>\n",
       "      <td>215</td>\n",
       "      <td>354</td>\n",
       "      <td>169</td>\n",
       "      <td>228</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bible-kjv.txt</th>\n",
       "      <td>443</td>\n",
       "      <td>165</td>\n",
       "      <td>475</td>\n",
       "      <td>3807</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blake-poems.txt</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bryant-stories.txt</th>\n",
       "      <td>110</td>\n",
       "      <td>154</td>\n",
       "      <td>23</td>\n",
       "      <td>144</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>burgess-busterbrown.txt</th>\n",
       "      <td>46</td>\n",
       "      <td>56</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carroll-alice.txt</th>\n",
       "      <td>70</td>\n",
       "      <td>73</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chesterton-ball.txt</th>\n",
       "      <td>139</td>\n",
       "      <td>117</td>\n",
       "      <td>69</td>\n",
       "      <td>198</td>\n",
       "      <td>90</td>\n",
       "      <td>75</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chesterton-brown.txt</th>\n",
       "      <td>132</td>\n",
       "      <td>170</td>\n",
       "      <td>71</td>\n",
       "      <td>111</td>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chesterton-thursday.txt</th>\n",
       "      <td>116</td>\n",
       "      <td>148</td>\n",
       "      <td>71</td>\n",
       "      <td>109</td>\n",
       "      <td>56</td>\n",
       "      <td>54</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edgeworth-parents.txt</th>\n",
       "      <td>503</td>\n",
       "      <td>420</td>\n",
       "      <td>127</td>\n",
       "      <td>517</td>\n",
       "      <td>160</td>\n",
       "      <td>271</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>melville-moby_dick.txt</th>\n",
       "      <td>421</td>\n",
       "      <td>215</td>\n",
       "      <td>183</td>\n",
       "      <td>379</td>\n",
       "      <td>230</td>\n",
       "      <td>181</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milton-paradise.txt</th>\n",
       "      <td>49</td>\n",
       "      <td>62</td>\n",
       "      <td>98</td>\n",
       "      <td>161</td>\n",
       "      <td>116</td>\n",
       "      <td>55</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shakespeare-caesar.txt</th>\n",
       "      <td>40</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>129</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shakespeare-hamlet.txt</th>\n",
       "      <td>60</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>131</td>\n",
       "      <td>56</td>\n",
       "      <td>52</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shakespeare-macbeth.txt</th>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whitman-leaves.txt</th>\n",
       "      <td>85</td>\n",
       "      <td>49</td>\n",
       "      <td>26</td>\n",
       "      <td>261</td>\n",
       "      <td>85</td>\n",
       "      <td>42</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         would  could  might  will   may  should  can\n",
       "austen-emma.txt            815    825    322   559   213     366  270\n",
       "austen-persuasion.txt      351    444    166   162    87     185  100\n",
       "austen-sense.txt           507    568    215   354   169     228  206\n",
       "bible-kjv.txt              443    165    475  3807  1024     768  213\n",
       "blake-poems.txt              3      3      2     3     5       6   20\n",
       "bryant-stories.txt         110    154     23   144    18      38   75\n",
       "burgess-busterbrown.txt     46     56     17    19     3      13   23\n",
       "carroll-alice.txt           70     73     28    24    11      27   57\n",
       "chesterton-ball.txt        139    117     69   198    90      75  131\n",
       "chesterton-brown.txt       132    170     71   111    47      56  126\n",
       "chesterton-thursday.txt    116    148     71   109    56      54  117\n",
       "edgeworth-parents.txt      503    420    127   517   160     271  340\n",
       "melville-moby_dick.txt     421    215    183   379   230     181  220\n",
       "milton-paradise.txt         49     62     98   161   116      55  107\n",
       "shakespeare-caesar.txt      40     18     12   129    35      38   16\n",
       "shakespeare-hamlet.txt      60     26     28   131    56      52   33\n",
       "shakespeare-macbeth.txt     42     15      5    62    30      41   21\n",
       "whitman-leaves.txt          85     49     26   261    85      42   88"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(cfd)\n",
    "df=df.transpose()\n",
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e458ed5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topmost modal in the highest frequency difference was most used in the text bible-kjv.txt\n",
      "The bottom most modal in the highest frequency difference was most used in the text bible-kjv.txt\n"
     ]
    }
   ],
   "source": [
    "#Text that uses the words'might' and 'will' the most\n",
    "max_text_least_word=df[least_used_word].idxmax()\n",
    "max_text_most_word=df[most_used_word].idxmax()\n",
    "print('The topmost modal in the highest frequency difference was most used in the text',max_text_most_word)\n",
    "print('The bottom most modal in the highest frequency difference was most used in the text',max_text_least_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45b9c7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topmost modal in the highest frequency difference was least used in the text blake-poems.txt\n",
      "The bottom most modal in the highest frequency difference was least used in the text blake-poems.txt\n"
     ]
    }
   ],
   "source": [
    "#Text that uses the words'might' and 'will' the least\n",
    "min_text_least_word=df[least_used_word].idxmin()\n",
    "min_text_most_word=df[most_used_word].idxmin()\n",
    "print('The topmost modal in the highest frequency difference was least used in the text',min_text_most_word)\n",
    "print('The bottom most modal in the highest frequency difference was least used in the text',min_text_least_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3270e298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package inaugural to\n",
      "[nltk_data]     C:\\Users\\sneha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\inaugural.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import inaugural\n",
    "nltk.download('inaugural')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93156de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kennedy_words = nltk.corpus.inaugural.words('1961-Kennedy.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82c0848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most frequently used long words are ['citizens', 'President', 'Americans', 'generation', 'forebears', 'revolution', 'committed', 'powerful', 'supporting', 'themselves']\n"
     ]
    }
   ],
   "source": [
    "kennedy_words_fd_greater_than_n=nltk.FreqDist((word) for word in kennedy_words if len(word)>7)\n",
    "kennedy_words_fd=nltk.FreqDist(dict(kennedy_words_fd_greater_than_n.most_common()[:10]))\n",
    "kennedy_words_fd=list(kennedy_words_fd.keys())\n",
    "print('10 most frequently used long words are',kennedy_words_fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d0259f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\sneha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\omw-1.4.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "01397812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "syn_dict={}\n",
    "hyp_dict={}\n",
    "for word_k in kennedy_words_fd:\n",
    "    for syn in wn.synsets(word_k):\n",
    "        synonyms_list=[]\n",
    "        hyp_list=[]\n",
    "        for l in syn.lemmas():\n",
    "            synonyms_list.append(l.name())\n",
    "            hyp_list=list(chain(*[l.lemma_names() for l in syn.hyponyms()]))\n",
    "    syn_dict[word_k]=synonyms_list\n",
    "    hyp_dict[word_k]=hyp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b0f91b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'themselves'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_count={}\n",
    "for s,hyp in hyp_dict.items():\n",
    "    hyp_count[s]=len(hyp)\n",
    "max(hyp_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
